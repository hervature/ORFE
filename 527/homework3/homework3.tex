\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{datetime}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage[USenglish]{babel}
\usepackage{matlab-prettifier}
\usepackage{graphicx}
\usepackage[makeroom]{cancel}
\usepackage{afterpage}
\usepackage{capt-of}

\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

\newtheoremstyle{colon}{\topsep}{\topsep}{}{}{\bfseries}{:}{ }{}
\theoremstyle{colon}
\newtheorem{exercise}{Exercise}
\newtheorem*{answer}{Answer}

\title{ORFE 527: Stochastic Calculus \\ Homework 3}
\author{Zachary Hervieux-Moore}

\newdate{date}{11}{03}{2017}
\date{\displaydate{date}}

\begin{document}

\maketitle

\clearpage

\begin{exercise}
  (Hitting time of drifted Brownian motion) Let $c, \mu \in \mathbb{R}$ and consider the hitting time level $c$ by a Brownian motion with drift $\mu$:
  \begin{gather*}
    \tau_c := \inf \{ t \geq 0 : B_t + \mu t = c \}
  \end{gather*}
  Show that the Laplace transform of $\tau_c$ is given by
  \begin{gather*}
    \mathbb{E} [e^{-u \tau_c}] = e^{\mu c - \lvert c \rvert \sqrt{\mu^2 + 2u}}, u \geq 0
  \end{gather*}
\end{exercise}

\begin{answer}
  We have a Brownian motion with drift. We wish to apply Girsanov's theorem to work in a space that does not have the drift. Suppose we have a standard Brownian motion $B_t$. Define our exponential as
  \begin{gather*}
    Z_t(\mu) = e^{-\mu B_t - \frac{1}{2}\mu^2 t}
  \end{gather*}
  From Homework 2, question 2, this is a martingale. By Girsanov's
  \begin{gather*}
    W_t = B_t + \mu t
  \end{gather*}
  Where $W_t$ is standard Brownian under $\tilde{\mathbb{P}}$. Note that this is precisely our Brownian motion with drift. Suppose $c > 0$. We have
  \begin{gather*}
    \mathbb{E}_{\mathbb{P}}[e^{-u \tau_c}] = \mathbb{E}_{\tilde{\mathbb{P}}}[ e^{-u \tau_c} \frac{ \text{d} \mathbb{P}}{\text{d} \mathbb{\tilde{P}}} ] = \mathbb{E}_{\tilde{\mathbb{P}}}[ e^{-u \tau_c} e^{\mu B_{\tau_c} + \frac{1}{2} \mu^2 \tau_c} ] \\
    = \mathbb{E}_{\tilde{\mathbb{P}}}[ e^{-u \tau_c} e^{\mu (c - \mu \tau_c) + \frac{1}{2} \mu^2 \tau_c} ] = e^{\mu c} \mathbb{E}_{\tilde{\mathbb{P}}}[ e^{-\frac{1}{2} (\mu^2 + 2u) \tau_c} ]
  \end{gather*}
  We also have that
  \begin{gather*}
    \tilde{\mathbb{P}}( \tau_c < \infty) = 1
  \end{gather*}
  Because $X_t$ is a standard Brownian motion under $\tilde{\mathbb{P}}$. So, we have an almost surely bounded stopping time so we can apply Optional Sampling Theorem to the martingale $e^{a B_t - \frac{1}{2} a^2t}$ at times 0 and $\tau_c$,
  \begin{gather*}
    1 = e^{a c} \mathbb{E}_{\tilde{\mathbb{P}}}[ e^{-\frac{1}{2} a^2 \tau_c} ] \\
    e^{-a c} = \mathbb{E}_{\tilde{\mathbb{P}}}[ e^{-\frac{1}{2} a^2 \tau_c} ]
  \end{gather*}
  Now, let $a^2 = (\mu^2 + 2u)$, so we have
  \begin{gather*}
    e^{- c \sqrt{\mu^2 + 2u}} = \mathbb{E}_{\tilde{\mathbb{P}}}[ e^{-\frac{1}{2} (\mu^2 + 2u) \tau_c} ]
  \end{gather*}
  Putting this into our expression from before,
  \begin{gather*}
    \mathbb{E}_{\mathbb{P}}[e^{-u \tau_c}] = e^{\mu c} e^{- c \sqrt{\mu^2 + 2u}} = e^{\mu c - c \sqrt{\mu^2 + 2u}}
  \end{gather*}
  By symmetry, we must have $\mathbb{E}_{\mathbb{P}}[e^{-u \tau_{-c}}] = \mathbb{E}_{\mathbb{P}}[e^{-u \tau_c}]$ where
  \begin{gather*}
    \tau_{-c} := \inf \{ t \geq 0 : -B_t - \mu t = -c \}
  \end{gather*}
  Notice that we must negate both $\mu$ and $c$, thus we conclude that
  \begin{gather*}
    \mathbb{E}_{\mathbb{P}}[e^{-u \tau_c}] = e^{\mu c} e^{- c \sqrt{\mu^2 + 2u}} = e^{\mu c - \lvert c \rvert \sqrt{\mu^2 + 2u}}
  \end{gather*}
\end{answer}

\clearpage

\begin{exercise}
  (Wald Identity) Let $\Omega := C([0, \infty))$ be the space of continuous functions, $\mathcal{F}$ be the Borel $\sigma$-algebra on $C([0, \infty))$ with respect to uniform convergence on compacts, and $(\mathcal{F}_t)_{t \geq 0}$ be the filtration generated by the projections $\Omega \rightarrow \mathbb{R}$, $f \mapsto f(t)$ for $t \geq 0$. Let $\mu \in \mathbb{R}$ and $\tau$ be a stopping time with respect to $(\mathcal{F}_t)_{t \geq 0}$ such that $\tau < \infty$ with probability 1 under the law of a Brownian motion with drift $\mu$. Show that
  \begin{gather*}
    \mathbb{E} \left[ e^{\mu B_\tau - \mu^2 \tau/2} \right] = 1
  \end{gather*}
  for a standard Brownian motion $B$.
\end{exercise}

\begin{answer}
  We have that
  \begin{gather*}
    \mathbb{E} \left[ e^{\mu B_t - \mu^2 \tau/2} \right] = \int_\Omega e^{\mu B_t - \mu^2 \tau/2} \text{d} \mathbb{P}(\omega)
  \end{gather*}
  We know that $e^{\mu B_t - \mu^2 \tau/2}$ is a martingale. Thus we can set $Z_t(\mu) = e^{\mu B_t - \mu^2 t/2}$ and use Girsanov's theorem on a finite time interval $[0,k]$ to get
  \begin{gather*}
    \mathbb{E} \left[ 1_{\{\tau \leq k\}} e^{\mu B_\tau - \mu^2 \tau/2} \right] = \int_\Omega 1_{\{\tau \leq k\}} e^{\mu B_\tau - \mu^2 \tau/2} \text{d} \mathbb{P}(\omega) \\
    = \int_\Omega 1_{\{\tau \leq k\}} \text{d} \mathbb{\tilde{P}}(\omega) = \mathbb{\tilde{P}} (\tau \leq k)
  \end{gather*}
  Where $\mathbb{\tilde{P}}$ is the law of a Brownian motion with drift $\mu$. As $k \rightarrow \infty$, the RHS is 1 by assumption. That is, $\mathbb{\tilde{P}} (\tau = \infty) = 0$. We also have by Monotone Convergence Theorem that
  \begin{gather*}
    \lim_{k \rightarrow \infty} \mathbb{E} \left[ 1_{\{\tau \leq k\}} e^{\mu B_\tau - \mu^2 \tau/2} \right] = \mathbb{E} \left[ e^{\mu B_\tau - \mu^2 \tau/2} \right]
  \end{gather*}
  So we conclude that
  \begin{gather*}
    \mathbb{E} \left[ e^{\mu B_\tau - \mu^2 \tau/2} \right] = 1
  \end{gather*}
\end{answer}

\clearpage

\begin{exercise}
  (Non-uniqueness) Consider the SDE
  \begin{gather*}
    \text{d} X_t = 3 X_t^{1/3} \text{d} t + 3 X_t^{2/3} \text{d} B_t
  \end{gather*}
  where $B$ is standard Brownian motion. Show that for any initial condition $x_0$ this SDE has uncountably infinitely many strong solutions.
\end{exercise}

\begin{answer}
  We have that the SDE is trivially satisfied by $X_t = 0$ with $x_0 = 0$. Now, consider $X_t = (B_t + x_0^{1/3})^3$, where $B_t$ is standard Brownian. Then we have $X_0 = x_0$ and by Ito's
  \begin{gather*}
    \text{d} X_t = 3(B_t + x_0^{1/3})^2 \text{d} B_t + \frac{1}{2} \cdot 3 \cdot 2 (B_t + x_0^{1/3}) \text{d} t \\
    = 3 X_t^{1/3} \text{d} t + 3 X_t^{2/3} \text{d} B_t
  \end{gather*}
  Since $B_t$ is Brownian, every state is recurrent and so there are $\tau_1, \tau_2, \mathellipsis$ countably infinite times that $B_t = - x_0^{1/3}$. Now, pick any subset of the natural numbers $I \subseteq \mathbb{N}$ and use these as an indicator set for when you'll switch between the two solutions
  \begin{gather*}
    X_t = \begin{cases}
      (B_t + x_0^{1/3})^3 & \text{ for } t \in [0, \tau_1] \\
      (B_t + x_0^{1/3})^3 & \text{ for } t \in [\tau_i, \tau_{i+1}] \text{ if } i \in I \\
      0 & \text{ for } t \in [\tau_i, \tau_{i+1}] \text{ if } i \notin I
    \end{cases}
  \end{gather*}
  We confirm that $X_0 = x_0$ and that the SDE is satisfied by the same steps as before. The number of possible subsets of $I$ is $2^{\mathbb{N}}$ which is uncountably many. We conclude that there are uncountably many strong solutions.
\end{answer}

\clearpage

\begin{exercise}
  (Doss-Sussmann method) Let $b : \mathbb{R} \rightarrow \mathbb{R}$ be a Lipschitz function and $\sigma : \mathbb{R} \rightarrow \mathbb{R}$ be twice continuously differentiable with bounded derivatives. In addition, for any $x \in \mathbb{R}$ consider the solution of the ODE
  \begin{gather*}
    \partial_t h(t,x) = \sigma(h(t,x)), h(0,x) = x
  \end{gather*}
  Finally, let $D_t$, $t \geq 0$ be the solution of the random ODE
  \begin{gather*}
    \frac{\text{d} D_t}{\text{d}t} = b(h(B_t, D_t)) \text{exp} \left( - \int_0^{B_t} \sigma'(h(s, D_t)) \text{d} s \right), D_0 = y
  \end{gather*}
  for a standard Brownian motion $B$ and $y \in \mathbb{R}$. Find the SDE satisfied by $X_t := h(B_t, D_t)$, $t \geq 0$ and verify that $X$ is its unique strong solution.

  \textit{Hint: start by finding the ODS satisfied by $g(t,x) := \partial_x h(t,x)$ and writing a formula for its solution.}
\end{exercise}

\begin{answer}
  As per the hint, we have
  \begin{align*}
    g(t,x) &= \partial_x h(t,x) \\
    \implies \partial_t g(t,x) &= \partial_t \partial_x h(t,x) \\
    &= \partial_x \partial_t h(t,x) \\
    &= \partial_x \sigma(h(t,x)) \\
    &= \sigma'(h(t,x)) \partial_x h(t,x) \\
    &= \sigma'(h(t,x)) g(t,x)
  \end{align*}
  Where we can swap the derivatives by Clairaut's theorem. We also have that $g(0,x) = \partial_x h(0,x) = \partial_x x = 1$. Thus, the solution for $g(t,x)$ is an exponential
  \begin{gather*}
    g(t,x) = e^{\int_0^t \sigma'(h(s,x)) ds}
  \end{gather*}
  Now, we write out the SDE for $X_t$ using Ito's formula in multiple variables, and use the fact that $D_t$ has bounded variation (from its definition, $\text{d} D_t$ is bounded since $b$ is Lipschitz and the exponential is also bounded) so that some of the cross variation terms are 0,
  \begin{align*}
    \text{d} X_t &= \frac{\partial}{\partial t} h(B_t,D_t) \text{d} B_t  + \frac{\partial}{\partial x} h(B_t,D_t) \text{d} D_t + \frac{1}{2} \frac{\partial^2}{\partial t^2} h(B_t,D_t) \text{d} t \\
    &= \sigma(h(B_t,D_t)) \text{d} B_t + g(B_t,D_t) \text{d} D_t + \frac{1}{2} \frac{\partial}{\partial t} \sigma(h(B_t,D_t)) \text{d} t\\
    &= \sigma(X_t) \text{d} B_t + e^{\int_0^{B_t} \sigma'(h(s,D_t)) ds} \cdot b(h(B_t, D_t)) e^{-\int_0^{B_t} \sigma'(h(s,D_t)) ds} \text{d} t \\
    &\quad + \frac{1}{2} \sigma'(h(B_t,D_t)) \frac{\partial}{\partial t} h(B_t, D_t) \text{d} t \\
    &= \sigma(X_t) \text{d} B_t + b(X_t) \text{d} t + \frac{1}{2} \sigma'(h(B_t,D_t)) \sigma(h(B_t,D_t)) \text{d} t \\
    &= \sigma(X_t) \text{d} B_t + (b(X_t) + \sigma'(X_t) \sigma(X_t)) \text{d} t
  \end{align*}
  Therefore, $X_t = h(B_t, D_t)$ solves the SDE
  \begin{gather*}
    \text{d} X_t = \sigma(X_t) \text{d} B_t + (b(X_t) + \sigma'(X_t) \sigma(X_t)) \text{d} t \\
    \text{with } X_0 = h(B_0, D_0) = h(0,y) = y
  \end{gather*}
  Now, to show uniqueness of this strong solution, we can show that the coefficients are Lipschitz. By assumption, $b$ is Lipschitz. $\sigma$ is Lipschitz since it has bounded derivatives (say by $M$). By the Mean Value Theorem,
  \begin{gather*}
    \sigma(x) - \sigma(y) = \sigma'(c) (x-y) \text{ for some } c \in \mathbb{R} \\
    \Leftrightarrow \lvert \sigma(x) - \sigma(y) \rvert = \lvert x - y \rvert \lvert \sigma'(c) \rvert \\
    \Leftrightarrow \lvert \sigma(x) - \sigma(y) \rvert \leq M \lvert x - y \rvert
  \end{gather*}
  Since adding Lipschitz functions is still Lipschitz by the triangle inequality, we just have to show that $\sigma'(\cdot) \sigma(\cdot)$ is locally Lipschitz. We have by triangle inequality
  \begin{gather*}
    \lvert \sigma'(x) \sigma(x) - \sigma'(y) \sigma(y) \rvert = \lvert \sigma'(x) \sigma(x) - \sigma'(x) \sigma(y) + \sigma'(x) \sigma(y) - \sigma'(y) \sigma(y) \rvert \\
    \leq \lvert \sigma'(x) \sigma(x) - \sigma'(x) \sigma(y) \lvert + \rvert \sigma'(x) \sigma(y) - \sigma'(y) \sigma(y) \rvert \\
    \leq \lvert \sigma'(x) \rvert \lvert \sigma(x) - \sigma(y) \rvert + \lvert \sigma(y) \rvert \lvert \sigma'(x) - \sigma'(y) \rvert
  \end{gather*}
  Now, we have that the derivatives are bounded. Therefore, $\sigma(\cdot)$ and $\sigma'(\cdot)$ are Lipschitz as shown previously. By assumption $\lvert \sigma'(x) \rvert \leq M$, and $\lvert \sigma(y) \rvert \leq N < \infty$ since it is continuous and $y$ is part of some compact set. Therefore, we have
  \begin{gather*}
    \lvert \sigma'(x) \sigma(x) - \sigma'(y) \sigma(y) \rvert \\
    \leq M K_\sigma \lvert x - y \rvert + N K_{\sigma'} \lvert x - y \rvert \\
    = (M K_\sigma + N K_{\sigma'}) \lvert x - y \rvert
  \end{gather*}
  Therefore, $\sigma'(\cdot) \sigma(\cdot)$ is locally Lipschitz. Hence, all the coefficients are locally Lipschitz and we conclude that the strong solution is unique.
\end{answer}

\end{document}